{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15) Data in Time - Processes and Concurrency <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programs and processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run an individual program, your operating system creates a single process. It uses system resources and data structure in the operating system's kernel. A process is isolated from other processes, it can not see what other processes are doing or interfere with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access process data from your own programs. The standard library's os module provides a common way of accessing some system information. For instance, we can obtain the process ID with os.getpid(), the current working directory from os.getcwd(), and the user ID and group ID with os.getuid() and os.getgid()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run a Python function as a separate process, or even create multiple independent processes with the multiprocessing module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import psutil\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(name):\n",
    "    print('Process number {}: {}'.format(os.getpid(), name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(5):\n",
    "    p = multiprocessing.Process(target = function, args = (\"I'm function number {}\".format(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you created one or more processes and want to terminate one for some reason, use terminate(). The standard os package procides a lot of details on your system, and lets you control some of it if you run your Python script as a privileged user. Besides file and directory functions, it has informational functions such as os.getuname() and os.cpu_count(). The third party package psutil also provides system and process information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[scputimes(user=1507.265625, system=3347.546875, idle=263258.984375, interrupt=1052.578125, dpc=738.625),\n",
       " scputimes(user=1933.125, system=973.015625, idle=265207.4375, interrupt=49.84375, dpc=16.421875),\n",
       " scputimes(user=8369.078125, system=6302.890625, idle=253441.609375, interrupt=82.046875, dpc=6.140625),\n",
       " scputimes(user=1436.1875, system=1399.90625, idle=265277.484375, interrupt=27.0, dpc=2.96875),\n",
       " scputimes(user=1772.5, system=982.765625, idle=265358.3125, interrupt=36.8125, dpc=3.890625),\n",
       " scputimes(user=1785.375, system=959.15625, idle=265369.046875, interrupt=40.921875, dpc=3.34375),\n",
       " scputimes(user=1553.3125, system=2623.21875, idle=263937.046875, interrupt=30.84375, dpc=4.78125),\n",
       " scputimes(user=1551.625, system=875.5625, idle=265686.390625, interrupt=32.984375, dpc=3.265625),\n",
       " scputimes(user=1568.609375, system=802.625, idle=265742.34375, interrupt=30.375, dpc=3.28125),\n",
       " scputimes(user=1563.3125, system=902.765625, idle=265647.5, interrupt=30.1875, dpc=3.453125),\n",
       " scputimes(user=1643.03125, system=1380.0625, idle=265090.484375, interrupt=49.765625, dpc=5.671875),\n",
       " scputimes(user=29447.703124999996, system=2972.359375, idle=235693.5, interrupt=36.59375, dpc=2.75),\n",
       " scputimes(user=1534.28125, system=945.0, idle=265634.28125, interrupt=38.578125, dpc=3.65625),\n",
       " scputimes(user=1504.328125, system=1194.296875, idle=265414.9375, interrupt=37.421875, dpc=4.546875),\n",
       " scputimes(user=18529.343749999996, system=2828.859374999971, idle=246755.359375, interrupt=49.90625, dpc=4.578125),\n",
       " scputimes(user=2934.984375, system=1341.6875, idle=263836.890625, interrupt=53.609375, dpc=8.875)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much time each CPU (of which we have 16) is using\n",
    "\n",
    "psutil.cpu_times(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How busy the CPUs are\n",
    "\n",
    "psutil.cpu_percent(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.5,\n",
       " 0.5,\n",
       " 4.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 1.2,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 4.8,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 4.3,\n",
       " 1.4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How busy the CPUs are per CPU\n",
    "\n",
    "psutil.cpu_percent(percpu = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run command from the shell using invoke. One use of invoke is to make functions available as command-line arguments. We simply decorate a function with @task from invoke.task. The function requires a first argument that is used internally by invoke, but it can be named an argument. These tasks can have arguments and you can invoke multiple tasks at one time from the command line (similar to && use in shell scripts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computers, if you are waiting for something, it is usually for one of two reasons:\n",
    "\n",
    "    I/O bound\n",
    "    \n",
    "    This is by far the most common. Computer CPUs are incredibly fast - hundreds of times faster than computer memory and many thousands of times faster than disks or networks.\n",
    "    \n",
    "    CPU bound\n",
    "    \n",
    "    The CPU keeps busy. This happens with number crunching tasks such as scientific or graphic calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two more terms are related to concurrency:\n",
    "\n",
    "    Synchronous - One thing follows the other.\n",
    "    Asynchronous - Tasks are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a single machine, if you want to perform multiple tasks as fast as possible, you want to make them independent. The trick is getting them all to work with one another. Any shared control or state means that there will be bottlenecks. An even bigger trick is dealing with failures, because concurrent computing is harder than regular computing. The first way to manage tasks is queues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A queue is like a list: things are added at one end and taken away from the other. Queues transport messages, which can be any kind of information. In this case, we are interested in queues for distributed task management, also known as work queues, job queues or task queues. Consider washing the dishes: washing, drying and putting away dishes may take a long time for an individual person if you individually wash, dry and store each dish in turn. This can be sped up by batch washing, batch drying and batch storing all the dishes together. Even quicker is to have multiple people: give each dish in the sink to an available washer, who washes it and hands it off to the first available dryer, who dries and hands it to a storer. This can be synchronous (workers wait for a dish to handle) or asynchronous (dishes are stacked between workers with different paces)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single machine, the standard library's multiprocessing modules contains a Queue function. Let us simulate a single washer and multiple dryer processes and an intermediate dish_queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washing 1 dish\n",
      "Washing 2 dish\n",
      "Washing 3 dish\n",
      "Washing 4 dish\n",
      "Washing 5 dish\n",
      "Drying 1 dish\n",
      "Drying 2 dish\n",
      "Drying 3 dish\n",
      "Drying 4 dish\n",
      "Drying 5 dish\n"
     ]
    }
   ],
   "source": [
    "# Simulating a washer and dryer chain process \n",
    "\n",
    "dishes = ['1', '2', '3', '4', '5']\n",
    "dish_queue = multiprocessing.JoinableQueue()\n",
    "\n",
    "for dish in dishes:\n",
    "    print('Washing', dish, 'dish')\n",
    "    dish_queue.put(dish)\n",
    "    \n",
    "while not dish_queue.empty():\n",
    "    dish = dish_queue.get()\n",
    "    print('Drying', dish, 'dish')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A thread runs within a process with access to everything in the process. The multiprocessing module has a similar module called threading that uses threads instead of processes. One difference between multiprocessing and threading is that threading does not have a terminate() function, there is no easy way to terminate a running thread. Like manual memory management in languages such as C and C++, threading can cause bugs that are hard to find, let alone fix. To use threads, all code in the program must be thread safe, this include not letting threads share any global variables, so they can run independently without breaking anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threads can be useful and safe when global data is not involved. In particular, threads are useful for saving time while waiting for some I/O operation to complete. In these cases, they do not have to fight over data, because each has completely separate variables. In Python, threads do not speed up CPU-bound tasks. For Python, the recommendations are as follows:\n",
    "\n",
    "    - Use threads for I/O bound problems.\n",
    "    - Use processes, networking or event for CPU bound problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Green threads and gevent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developers traditionally avoid slow spots in programs by running them in separate threads or processes. One alternative is event-based programming. An event-based program runs a central event loop, doles out any tasks and repeats the loop. The gevent library is event-based and lets you write normal imperative code and converts pieces to coroutines. These are like generators that communicate with one another and keep track of where they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module makes use of greenlets (also known sometimes as a green thread or a microthread). The difference from a normal thread is that it does not block. If something occurred that would have blocked a normal thread, gevent switches control to one of the other greenlets. There are potential dangers when using gevent. As with any event-based system, each chunk of code that you execute should be relatively quick. Although it is non-blocking, code that does a lot of work is still slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python 3.4, Python added a standard asynchornous module called asyncio. Python 3.5 then added the keywords async and await. These implement some new concepts:\n",
    "\n",
    "    - Coroutines are functions that pause at various points.\n",
    "    - An event loop that schedules and runs coroutines.\n",
    "    \n",
    "These let us write asynchronous code that looks something like the normal synchronous code that we are used to. The event loop provides cooperative multitasking, in which coroutines indicate when they are able to start and stop. They run in a single thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You define a coroutine by putting async before its initial def. You call a coroutine by:\n",
    "\n",
    "    - Putting await before it, which adds the coroutine to an existing event loop. You can do this only within another coroutine.\n",
    "    - Or by using asyncio.run(), which explicitly starts an event loop.\n",
    "    - Or by using asyncio.create_task() or asyncio.sensure_feature()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example where we create a task and await it. We use the asyncio.sleep(0 function to simulate a process taking time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating to asynchronous tasks (one that takes 5 seconds, one that takes 2 seconds)\n",
    "\n",
    "async def task(start, seconds, end):\n",
    "    print(start)\n",
    "    await asyncio.sleep(seconds)\n",
    "    print(end)\n",
    "    \n",
    "async def workers():\n",
    "    task_1 = asyncio.create_task(task('Task 1 - Beginning', 5, 'Task 1 - Done'))\n",
    "    task_2 = asyncio.create_task(task('Task 2 - Beginning', 2, 'Task 2 - Done'))\n",
    "    await task_1\n",
    "    await task_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Beginning\n",
      "Task 2 - Beginning\n",
      "Task 2 - Done\n",
      "Task 1 - Done\n"
     ]
    }
   ],
   "source": [
    "# Run the two tasks (Outside Jupyter we would use asyncio.run(workers()))\n",
    "\n",
    "await workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is no delay in the tasks starting because they were separate tasks. But task 2 finishes 2 seconds later and task 1 finishes just 3 seconds after that. We have essentially saved 2 seconds from a synchronous approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more moving parts, there are more possibilities for our assembly lines to be disrupted. Common techniques for potential problems include:\n",
    "\n",
    "    Fire and forget\n",
    "    Just pass things on and do not worry about the consequences, even if no one is there.\n",
    "    \n",
    "    Request-reply\n",
    "    The washer receives an acknowledgment from the dryer, and the dryer from the storer, for each dish in the pipeline.\n",
    "    \n",
    "    Back pressure\n",
    "    This technique directs a fast worker to take it easy if someone downstream can not keep up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real systems, you need to be careful that workers are keeping up with demand. You might add new tasks to a pending list, while some worker process removes the latest message and add it to a working list. When the message is done, it is removed from the working list and added to a completed list. This lets you know what tasks have failed or are taking too long. Some Python-based queue packages that add this extra level of management include:\n",
    "\n",
    "    celery - can execute distributed tasks synchronously or asynchronously, using the the methods above: multiprocessing, gevent, and others.\n",
    "    \n",
    "    rq - a Python library for job queues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
